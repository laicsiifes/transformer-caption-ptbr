{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prV_WIbS_yGK"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "from datasets import load_dataset\n",
        "from  tqdm import tqdm\n",
        "\n",
        "\n",
        "# model_tuple = ('vit_tucano_1b', 'TucanoBR/ViTucano-1b5-v1')\n",
        "model_tuple = ('vit_tucano_2b', 'TucanoBR/ViTucano-2b8-v1')\n",
        "\n",
        "outputs_dir = 'drive/MyDrive/Experimentos/gabriel/captions/'\n",
        "images_dir = 'images/'\n",
        "\n",
        "os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "outputs_dir = os.path.join(outputs_dir, model_tuple[0])\n",
        "\n",
        "os.makedirs(outputs_dir, exist_ok=True)\n",
        "\n",
        "max_length = 25\n",
        "\n",
        "prompt = f'Escreva uma descriÃ§Ã£o em portuguÃªs do Brasil para a imagem com no mÃ¡ximo {max_length} palavras.'"
      ],
      "metadata": {
        "id": "2VFAzUVm_1ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_dir"
      ],
      "metadata": {
        "id": "exo4qiTII7C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_hub = 'laicsiifes/flickr30k-pt-br-human-generated'\n",
        "\n",
        "print(f\"\\nLoading {dataset_hub}\")\n",
        "\n",
        "test_dataset = load_dataset(dataset_hub, split='test')\n",
        "\n",
        "print(f\"\\n\\tTotal of Examples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "VlmbfujIABWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f'\\nDevice: {device}')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_tuple[1])\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_tuple[1],\n",
        "    torch_dtype=torch.bfloat16, # for optimized inference  ðŸš€\n",
        "    trust_remote_code=True)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "9jECDiKoAFY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\nGenerating Captions Using {model_tuple[0]}\\n')\n",
        "\n",
        "outputs_file_path = os.path.join(outputs_dir, f'{model_tuple[0]}.json')\n",
        "\n",
        "dict_images_processed = {}\n",
        "\n",
        "if os.path.exists(outputs_file_path):\n",
        "    with open(file=outputs_file_path, mode='r', encoding='utf-8') as json_file:\n",
        "        output_data = json.load(json_file)\n",
        "        for example in output_data:\n",
        "            dict_images_processed[example['img_id']] = example\n",
        "\n",
        "list_generated_captions = []\n",
        "\n",
        "temp_image_path = f'{images_dir}/image.jpeg'\n",
        "\n",
        "with tqdm(total=len(test_dataset), colour='green', file=sys.stdout,\n",
        "          desc='Generating Captions') as pbar:\n",
        "\n",
        "    for example in test_dataset:\n",
        "\n",
        "        image = example['image']\n",
        "        img_id = example['img_id']\n",
        "        file_name = example['filename']\n",
        "        reference_captions = example['caption']\n",
        "\n",
        "        if img_id in dict_images_processed:\n",
        "            data = dict_images_processed[img_id]\n",
        "            list_generated_captions.append(data)\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        image.save(temp_image_path)\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                'role': 'user',\n",
        "                'content': [\n",
        "                    {\n",
        "                        'type': 'image'\n",
        "                    },\n",
        "                    {\n",
        "                        'type': 'text',\n",
        "                        'text': prompt\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        generated_caption, _ = model.chat(\n",
        "            prompt=prompt,\n",
        "            image=temp_image_path,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=max_length,\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        list_generated_captions.append(\n",
        "            {\n",
        "                'img_id': img_id,\n",
        "                'file_name': file_name,\n",
        "                'reference_captions': reference_captions,\n",
        "                'generated_caption': generated_caption\n",
        "            }\n",
        "        )\n",
        "\n",
        "        with open(file=outputs_file_path, mode='w', encoding='utf-8') as json_file:\n",
        "            json.dump(list_generated_captions, json_file, indent=4)\n",
        "\n",
        "        pbar.update(1)"
      ],
      "metadata": {
        "id": "LIcu_9gTARZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7E-mtQRCxwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}